{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNWjtEMh72bq9uAVtP8FQRX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SWESH1K/ThinkAI_Paper/blob/main/ResNet50.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plant Pest Prediction in Castor Plants"
      ],
      "metadata": {
        "id": "Tfcus8kPhR02"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Connecting the Google Drive"
      ],
      "metadata": {
        "id": "DWjGNqRbha3Z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UeEcAo1-gjOv",
        "outputId": "018bc9f4-198a-4918-ab59-aed782e5d7ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preprocessing"
      ],
      "metadata": {
        "id": "pxA1NdhzqPNq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importing Libraries"
      ],
      "metadata": {
        "id": "Y_DQD6Nuhnd7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "NK85FNZJhm6_"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seed_value = 42\n",
        "tf.random.set_seed(seed_value)"
      ],
      "metadata": {
        "id": "p7DvQfR3htAg"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading the Original Images"
      ],
      "metadata": {
        "id": "DVUugIMIiHWf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "orginal_data_set = tf.keras.utils.image_dataset_from_directory(\n",
        "    '/content/drive/MyDrive/Dataset/Training Set',\n",
        "    labels=\"inferred\",\n",
        "    label_mode=\"categorical\",\n",
        "    class_names=None,\n",
        "    color_mode=\"rgb\",\n",
        "    batch_size=32,\n",
        "    image_size=(224, 224),\n",
        "    shuffle=True,\n",
        "    seed=42,\n",
        "    validation_split=None,\n",
        "    subset=None,\n",
        "    interpolation=\"bilinear\",\n",
        "    follow_links=False,\n",
        "    crop_to_aspect_ratio=False\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mr1ZQqB2hvPB",
        "outputId": "ac5d5f68-0188-451f-fa12-8cfa2179d61b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 284 files belonging to 3 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading the Augmented Images"
      ],
      "metadata": {
        "id": "xKu8TFhViLLW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "augmented_data_set = tf.keras.utils.image_dataset_from_directory(\n",
        "    '/content/drive/MyDrive/Dataset/New Aug Images',\n",
        "    labels=\"inferred\",\n",
        "    label_mode=\"categorical\",\n",
        "    class_names=None,\n",
        "    color_mode=\"rgb\",\n",
        "    batch_size=32,\n",
        "    image_size=(224, 224),\n",
        "    shuffle=True,\n",
        "    seed=42,\n",
        "    validation_split=None,\n",
        "    subset=None,\n",
        "    interpolation=\"bilinear\",\n",
        "    follow_links=False,\n",
        "    crop_to_aspect_ratio=False\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CIIJBrXciNYR",
        "outputId": "7bb3a8d1-80c1-4247-84b1-e2a90a90274b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3840 files belonging to 3 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Combining the Original and Augmented Images"
      ],
      "metadata": {
        "id": "Wh9ZIoYXibSD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "total_dataset = orginal_data_set.concatenate(augmented_data_set)"
      ],
      "metadata": {
        "id": "PL3FOt_riVDM"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_images = []\n",
        "all_labels = []\n",
        "for images, labels in total_dataset.unbatch():\n",
        "  all_images.append(images)\n",
        "  all_labels.append(labels)\n",
        "# Convert the lists to TensorFlow tensors\n",
        "all_images = tf.stack(all_images)\n",
        "all_labels = tf.stack(all_labels)\n",
        "# Get the indices for each class\n",
        "class_0_indices = tf.where(tf.equal(all_labels[:, 0], 1))[:, 0]\n",
        "class_1_indices = tf.where(tf.equal(all_labels[:, 1], 1))[:, 0]\n",
        "class_2_indices = tf.where(tf.equal(all_labels[:, 2], 1))[:, 0]\n",
        "# Combine the indices for the full training sets\n",
        "train_indices = tf.concat([class_0_indices, class_1_indices, class_2_indices], axis=0)\n",
        "# Shuffle the training indices\n",
        "train_indices = tf.random.shuffle(train_indices, seed=seed_value)\n",
        "# Create the training and testing datasets\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((tf.gather(all_images, train_indices), tf.gather(all_labels, train_indices))).batch(32)\n",
        "# Verify the number of images in each dataset\n",
        "print(f\"Number of batches in training dataset: {len(list(train_dataset))}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZgiB_EtHijWn",
        "outputId": "2f1632e5-5f71-4262-bfa9-16b1e2086b6a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of batches in training dataset: 129\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building and Training the Model"
      ],
      "metadata": {
        "id": "bqdn2aUOosej"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import ResNet50\n",
        "import tensorflow as tf\n",
        "\n",
        "pre_model = ResNet50(\n",
        "    weights='imagenet',\n",
        "    include_top=False,\n",
        "    input_shape=(224, 224, 3)\n",
        ")\n",
        "\n",
        "pre_model.trainable = False\n",
        "\n",
        "model = tf.keras.models.Sequential()\n",
        "model.add(pre_model)\n",
        "model.add(tf.keras.layers.GlobalAveragePooling2D())\n",
        "model.add(tf.keras.layers.Dense(units=4096, activation='relu'))\n",
        "model.add(tf.keras.layers.Dropout(0.3))\n",
        "model.add(tf.keras.layers.Dense(units=512, activation='relu'))\n",
        "model.add(tf.keras.layers.Dropout(0.6))\n",
        "model.add(tf.keras.layers.Dense(units=2, activation='softmax'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gbc0uCQUoty4",
        "outputId": "af7ab754-d1eb-4efe-ad17-969ba1f47926"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.Adam(\n",
        "    learning_rate=0.0001),loss='categorical_crossentropy',metrics=['accuracy', 'precision', 'recall'])"
      ],
      "metadata": {
        "id": "cnAJnqG5ovAO"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "IcFtXzH6oy14",
        "outputId": "f2e4f083-4390-479e-a25f-6bf209303ebe"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ resnet50 (\u001b[38;5;33mFunctional\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m2048\u001b[0m)     │    \u001b[38;5;34m23,587,712\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling2d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4096\u001b[0m)           │     \u001b[38;5;34m8,392,704\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4096\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │     \u001b[38;5;34m2,097,664\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │         \u001b[38;5;34m1,026\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ resnet50 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">23,587,712</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling2d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">8,392,704</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,097,664</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,026</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m34,079,106\u001b[0m (130.00 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">34,079,106</span> (130.00 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m10,491,394\u001b[0m (40.02 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,491,394</span> (40.02 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m23,587,712\u001b[0m (89.98 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,587,712</span> (89.98 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = [\n",
        "    tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
        "    tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2)\n",
        "]"
      ],
      "metadata": {
        "id": "2t2Co7uDo004"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training_history = model.fit(x=train_dataset, validation_data=test_dataset, epochs=20, callbacks=callbacks)"
      ],
      "metadata": {
        "id": "VVw6-n7lo4Ec"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Accuracy Visualization"
      ],
      "metadata": {
        "id": "YY49C0v2pAiB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history_dict = training_history.history\n",
        "acc = history_dict['accuracy']\n",
        "val_acc = history_dict['val_accuracy']\n",
        "loss = history_dict['loss']\n",
        "val_loss = history_dict['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Plot accuracy\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs, acc, 'b', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'r', label='Validation accuracy') # Changed 'b' to 'r' for clarity\n",
        "plt.title('ResNet50: Training and validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "# Plot loss\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs, loss, 'b', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation loss') # Changed 'b' to 'r' for clarity\n",
        "plt.title('ResNet50: Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "PfI16LMVo6pL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluating the Model"
      ],
      "metadata": {
        "id": "EXwbSrDSpLO-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training Data"
      ],
      "metadata": {
        "id": "tvUnnr3QpVFZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Training set Accuracy\n",
        "train_loss, train_acc, train_prec, train_recall = model.evaluate(train_dataset)\n",
        "print('Training accuracy:', train_acc)"
      ],
      "metadata": {
        "id": "OTeVMGrBpGlK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Training Loss:', round(train_loss*100, 2), \"%.\")"
      ],
      "metadata": {
        "id": "AC3EWGgspPVc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "# Get true labels and predicted labels for the training dataset\n",
        "true_labels = []\n",
        "predicted_labels = []\n",
        "\n",
        "for images, labels in train_dataset:\n",
        "    true_labels.extend(tf.argmax(labels, axis=1).numpy())\n",
        "    predictions = model.predict(images)\n",
        "    predicted_labels.extend(tf.argmax(predictions, axis=1).numpy())\n",
        "\n",
        "print(len(true_labels))\n",
        "\n",
        "# Generate the confusion matrix\n",
        "cm = confusion_matrix(true_labels, predicted_labels)\n",
        "\n",
        "# Plot the confusion matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('ResNet50: Confusion Matrix on Training Data')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "WzVNIYhOpR4I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing Data"
      ],
      "metadata": {
        "id": "6WeeOMdNpa0B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Test set Accuracy\n",
        "test_loss, test_acc, test_prec, test_recall = model.evaluate(test_dataset)\n",
        "print('Validation accuracy:', test_acc)"
      ],
      "metadata": {
        "id": "_V3qgtlApbu2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Test Loss:', round(test_loss*100, 2), \"%\")"
      ],
      "metadata": {
        "id": "oAY76f9zpe9u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "# Get true labels and predicted labels for the training dataset\n",
        "true_labels = []\n",
        "predicted_labels = []\n",
        "\n",
        "for images, labels in test_dataset:\n",
        "    true_labels.extend(tf.argmax(labels, axis=1).numpy())\n",
        "    predictions = model.predict(images)\n",
        "    predicted_labels.extend(tf.argmax(predictions, axis=1).numpy())\n",
        "\n",
        "# Generate the confusion matrix\n",
        "cm = confusion_matrix(true_labels, predicted_labels)\n",
        "\n",
        "# Plot the confusion matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('ResNet50: Confusion Matrix on Testing Data')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ymBJrU8NphCn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Saving the Model"
      ],
      "metadata": {
        "id": "CVprC9HmpkiK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/drive/MyDrive/ICAR_IIOR/trained_plant_disease_model_augmented_classbalanced_resnet_imagenet_21_07_2025.keras')"
      ],
      "metadata": {
        "id": "AikMhzKqpmpR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Stratified K-Fold"
      ],
      "metadata": {
        "id": "g9Hwza9Qpvsj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Converting the Test Data into Numpy Arrays"
      ],
      "metadata": {
        "id": "Y4UeiLh8py3D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf # Import tensorflow\n",
        "\n",
        "# Initialize empty lists to store images and labels\n",
        "X_list = []\n",
        "y_list = []\n",
        "\n",
        "# Iterate through the combined training dataset (original + augmented data)\n",
        "for images, labels in train_dataset:\n",
        "    X_list.append(images.numpy())\n",
        "    y_list.append(labels.numpy())\n",
        "\n",
        "# Concatenate the lists of arrays into single NumPy arrays\n",
        "X = np.concatenate(X_list, axis=0)\n",
        "y_one_hot = np.concatenate(y_list, axis=0) # Keep the one-hot encoded labels if needed elsewhere\n",
        "\n",
        "# Convert one-hot encoded labels to class indices\n",
        "y = tf.argmax(y_one_hot, axis=1).numpy()\n",
        "\n",
        "# Now y has shape (num_samples,) with class indices"
      ],
      "metadata": {
        "id": "WWj87JkSpyOm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Applying the K-Fold"
      ],
      "metadata": {
        "id": "wmXrh9z1p9kd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "# Instantiate Stratified K-Fold\n",
        "n_splits = 5\n",
        "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "\n",
        "fold_accuracies = []\n",
        "fold_losses = []\n",
        "\n",
        "test_fold_accuracies = []\n",
        "test_fold_losses = []\n",
        "\n",
        "num_classes = 2  # Define your number of classes\n",
        "\n",
        "for fold, (train_index, val_index) in enumerate(skf.split(X, y)):\n",
        "    print(f\"\\n--- Fold {fold+1}/{n_splits} ---\")\n",
        "\n",
        "    # Split data\n",
        "    X_train, X_val = X[train_index], X[val_index]\n",
        "    y_train, y_val = y[train_index], y[val_index]\n",
        "\n",
        "    # One-hot encode labels\n",
        "    y_train_one_hot = tf.keras.utils.to_categorical(y_train, num_classes=num_classes)\n",
        "    y_val_one_hot = tf.keras.utils.to_categorical(y_val, num_classes=num_classes)\n",
        "\n",
        "    # Create TensorFlow datasets\n",
        "    train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train_one_hot)).batch(32)\n",
        "    val_dataset = tf.data.Dataset.from_tensor_slices((X_val, y_val_one_hot)).batch(32)\n",
        "\n",
        "    # Build model\n",
        "    pre_model = tf.keras.applications.ResNet50(\n",
        "        weights='imagenet',\n",
        "        include_top=False,\n",
        "        input_shape=(224, 224, 3)\n",
        "    )\n",
        "\n",
        "    pre_model.trainable = False\n",
        "\n",
        "    model = tf.keras.models.Sequential()\n",
        "    model.add(pre_model)\n",
        "    model.add(tf.keras.layers.GlobalAveragePooling2D())\n",
        "    model.add(tf.keras.layers.Dense(units=4096, activation='relu'))\n",
        "    model.add(tf.keras.layers.Dropout(0.3))\n",
        "    model.add(tf.keras.layers.Dense(units=512, activation='relu'))\n",
        "    model.add(tf.keras.layers.Dropout(0.6))\n",
        "    model.add(tf.keras.layers.Dense(units=2, activation='softmax'))\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
        "        loss='categorical_crossentropy',\n",
        "        # loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.1),\n",
        "        metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()]\n",
        "    )\n",
        "\n",
        "    callbacks = [\n",
        "        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True),\n",
        "        tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2)\n",
        "    ]\n",
        "\n",
        "    #Using class_weight to reduce overfitting due to class-imbalance\n",
        "    # from sklearn.utils import class_weight\n",
        "\n",
        "    # class_weights_array = class_weight.compute_class_weight(\n",
        "    #     class_weight='balanced',\n",
        "    #     classes=np.unique(y_train),\n",
        "    #     y=y_train\n",
        "    # )\n",
        "\n",
        "    # Convert to dictionary (this is essential)\n",
        "    # class_weights = dict(enumerate(class_weights_array))\n",
        "\n",
        "\n",
        "    # Train model\n",
        "    history = model.fit(train_dataset, validation_data=val_dataset, epochs=20, verbose=1, callbacks=callbacks)\n",
        "\n",
        "    # Evaluate model\n",
        "    loss, accuracy, precision, recall = model.evaluate(val_dataset, verbose=0)\n",
        "    print(f\"Validation Loss: {loss:.4f}, Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}\")\n",
        "    fold_losses.append(loss)\n",
        "    fold_accuracies.append(accuracy)\n",
        "\n",
        "    # Evaluating on X_test, y_test\n",
        "    y_test_one_hot = tf.keras.utils.to_categorical(y_test, num_classes=num_classes)\n",
        "    test_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test_one_hot)).batch(32)\n",
        "    loss, accuracy, precision, recall = model.evaluate(test_dataset, verbose=0)\n",
        "    print(f\"Test Loss: {loss:.4f}, Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}\")\n",
        "    test_fold_losses.append(loss)\n",
        "    test_fold_accuracies.append(accuracy)\n",
        "\n",
        "    # Prediction and analysis\n",
        "    y_val_preds = model.predict(X_val, verbose=0)\n",
        "    y_val_pred_labels = np.argmax(y_val_preds, axis=1)\n",
        "    y_val_true_labels = y_val\n",
        "\n",
        "    # Confident wrong predictions\n",
        "    pred_confidences = np.max(y_val_preds, axis=1)\n",
        "    incorrect_indices = np.where(y_val_pred_labels != y_val_true_labels)[0]\n",
        "    confident_wrong = [(i, y_val_pred_labels[i], y_val_true_labels[i], pred_confidences[i])\n",
        "                       for i in incorrect_indices if pred_confidences[i] > 0.9]\n",
        "\n",
        "    print(f\"→ {len(confident_wrong)} confidently wrong predictions (confidence > 0.9)\")\n",
        "    for i, pred, true, conf in confident_wrong[:3]:  # Show only first 3 for brevity\n",
        "        print(f\"Sample {i}: Predicted={pred}, True={true}, Confidence={conf:.2f}\")\n",
        "\n",
        "    # Confusion matrix\n",
        "    cm = confusion_matrix(y_val_true_labels, y_val_pred_labels)\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(cm)\n",
        "    print(\"Classification Report:\")\n",
        "    print(classification_report(y_val_true_labels, y_val_pred_labels))\n",
        "\n",
        "    # Confusion matrix for Test data\n",
        "    y_test_preds = model.predict(X_test, verbose=0)\n",
        "    y_test_pred_labels = np.argmax(y_test_preds, axis=1)\n",
        "    y_test_true_labels = y_test\n",
        "    cm_test = confusion_matrix(y_test_true_labels, y_test_pred_labels)\n",
        "    print(\"Confusion Matrix for Test Data:\")\n",
        "    print(cm_test)\n",
        "    print(\"Classification Report for Test Data:\")\n",
        "    print(classification_report(y_test_true_labels, y_test_pred_labels))\n",
        "\n",
        "# Summary\n",
        "print(\"\\n=== Overall Results ===\")\n",
        "print(f\"Average Validation Accuracy: {np.mean(fold_accuracies):.4f}\")\n",
        "print(f\"Std Dev of Validation Accuracy: {np.std(fold_accuracies):.4f}\")\n",
        "print(f\"Average Validation Loss: {np.mean(fold_losses):.4f}\")\n",
        "print(f\"Std Dev of Validation Loss: {np.std(fold_losses):.4f}\")\n",
        "print(f\"Average Test Accuracy: {np.mean(test_fold_accuracies):.4f}\")\n",
        "print(f\"Std Dev of Test Accuracy: {np.std(test_fold_accuracies):.4f}\")\n",
        "print(f\"Average Test Loss: {np.mean(test_fold_losses):.4f}\")\n",
        "print(f\"Std Dev of Test Loss: {np.std(test_fold_losses):.4f}\")"
      ],
      "metadata": {
        "id": "QXzOE9gTp_LS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}